# ED Dashboard

This package provides the subpackage and modules used to display statistical and RAG analyses data gathered from scraping runs


## Structure

The `dashboard` package has the following structure:

- a `pages` subpackage which contains the modules for each webpage generated by the internal 'plotly dash' webserver
- other modules required for the running and the server app and pages
  

## Usage

The dashboard is run via the following commands:

- `eds dash`

For detailed information on how to use the dashboard tool contained in this package, see the [eds cli doc](../../README.md)


## Running The Dashboard

Before running the `eds dash` command, perform these steps to ensure the dashboard displays up to date information about the scraping runs:

1. At least one scraper must have been run prior to launching the dashboard -- **compulsory step**

2. Run the `deduplicate`  transformer for all scrapers -- **optional**
    > Although marked 'optional', running this before every launch of the dashboard will speedup the dashboard startup time

3. Run the edscrapers stats script `eds stats` -- **compulsory step**

4. Run the edscrapers compare script `eds compare` -- **compulsory step**

5. Run at least one `sanitize` transformer process for one of the offices -- **optional**
    > Although marked as 'optional', running the sanitize process has the upside of improving the RAG score displayed on the dashobard

6. Run at least one `datajson` transformer process for one of the offices -- **compulsory step**

7. Run the `rag` transformer on each office/scraper -- **compulsory step**
